# User Guide

Complete guide to using the ARIA dashboard and understanding its outputs.

## Table of Contents

1. [Getting Started](#getting-started)
2. [Dashboard Overview](#dashboard-overview)
3. [Understanding Predictions](#understanding-predictions)
4. [Pattern Analysis](#pattern-analysis)
5. [Automation Approvals](#automation-approvals)
6. [Troubleshooting](#troubleshooting)

## Getting Started

### Accessing the Dashboard

1. Start the hub (if not already running):
   ```bash
   systemctl --user start aria-hub.service
   ```

2. Open your browser and navigate to:
   - Local: `http://localhost:8000/ui`
   - Remote (via Tailscale): `https://justin-linux.tail828051.ts.net:8000/ui`

### First-Time Setup

On first launch, the hub will:
1. Run discovery to scan your Home Assistant instance (~30 seconds)
2. Populate the cache with entities and capabilities
3. Display available capabilities on the dashboard

**Note:** ML predictions and patterns will not be available until:
- **ML Engine**: Needs 7 days of training data (from `ha-log-sync`)
- **Patterns**: Needs 24 hours of logbook data

## Dashboard Overview

### Home Page (`/ui`)

Shows system health and recent activity:

- **Hub Status**: Running/stopped, uptime, module count
- **Module Status**: Discovery, ML Engine, Patterns, Orchestrator
- **Recent Events**: Last 10 cache updates, discoveries, predictions
- **Quick Stats**: Entity count, capability count, automation proposals

### Discovery Page (`/ui/discovery`)

Shows results from the last capability scan:

- **Discovery Timestamp**: When the last scan completed
- **Entity Count**: Total entities discovered
- **Capability List**: All detected capabilities (lighting, power monitoring, etc.)
- **Entity Details**: Full entity list with states and attributes

**Refresh Discovery:**
Click "Run Discovery Now" to trigger a manual scan.

### Capabilities Page (`/ui/capabilities`)

Detailed view of each capability:

**For each capability:**
- **Entity Count**: Number of entities in this capability
- **Entity List**: All entities with current states
- **Availability**: Whether the capability is currently usable
- **Last Update**: When this capability was last refreshed

**Example capabilities:**
- `lighting`: All light entities
- `power_monitoring`: Sensors tracking power consumption
- `climate`: Thermostats and climate controls
- `occupancy`: Person and device tracker entities
- `doors_windows`: Door and window sensors

### Predictions Page (`/ui/predictions`)

Shows ML model predictions for entity states:

**Prediction Card Format:**
```
Entity: light.living_room
Predicted State: on
Confidence: 87%
Time Horizon: 15 minutes
Last Updated: 2026-02-11 14:30:00
```

**Understanding Confidence:**
- **90-100%**: Very high confidence - model is very certain
- **75-89%**: High confidence - reliable prediction
- **60-74%**: Medium confidence - use with caution
- **<60%**: Low confidence - prediction may be unreliable

**Time Horizons:**
- **5 min**: Very short-term prediction (immediate future)
- **15 min**: Short-term prediction (near future)
- **1 hour**: Medium-term prediction
- **4 hours**: Long-term prediction

**Prediction Types:**
- **Binary** (on/off): For lights, switches, binary sensors
- **Numeric**: For sensors (temperature, power, etc.)
- **Categorical**: For climate modes, media player states

### Patterns Page (`/ui/patterns`)

Shows detected behavioral patterns from LLM analysis:

**Pattern Card Format:**
```
Pattern: Evening Light Automation
Description: Living room lights turn on between 6-8 PM when occupancy detected
Frequency: Daily
Confidence: 0.92
Entities Involved:
  - light.living_room
  - binary_sensor.occupancy_living_room
Suggested Action: Create automation
```

**Pattern Types:**
- **Temporal**: Time-based patterns (e.g., "lights on at sunset")
- **Occupancy-based**: Patterns tied to presence detection
- **Environmental**: Patterns based on temperature, weather, etc.
- **Device correlation**: Multiple devices changing together

**Frequency Values:**
- **Daily**: Pattern occurs every day
- **Weekdays**: Pattern occurs Monday-Friday only
- **Weekends**: Pattern occurs Saturday-Sunday only
- **Weekly**: Pattern occurs once per week
- **Irregular**: Pattern has no consistent schedule

### Automations Page (`/ui/automations`)

Manage automation proposals generated by the hub:

**Proposal Card:**
```
Automation ID: auto_light_evening_01
Trigger: Time is 18:00
Conditions:
  - Occupancy sensor is on
  - Sun is below horizon
Actions:
  - Turn on light.living_room
  - Set brightness to 80%
Confidence: 0.88
Status: Pending Approval
```

**Actions:**
- **Approve**: Accept the automation (will be created in Home Assistant)
- **Reject**: Decline the automation
- **Edit**: Modify conditions or actions before approval

**Status Values:**
- **Pending**: Awaiting your review
- **Approved**: Approved, automation active in HA
- **Rejected**: Declined, will not be created
- **Failed**: Approval attempt failed (check logs)

### Insights Page (`/ui/insights`)

Cross-module analysis and correlations:

**Insight Types:**
1. **Prediction-Pattern Correlation**
   - Shows when ML predictions align with detected patterns
   - Example: "ML predicts light.kitchen on at 7 AM (95% confidence) matches detected morning routine pattern"

2. **Anomaly Detection**
   - Unusual behavior not matching known patterns
   - Example: "Lights activated at 3 AM (not part of any known pattern)"

3. **Capability Utilization**
   - Which capabilities are actively used vs. dormant
   - Example: "70% of lights automated, 30% manual only"

4. **Automation Effectiveness**
   - Success rate of approved automations
   - Example: "Evening lights automation triggered 28/30 days successfully"

## Understanding Predictions

### How Predictions Work

The ML engine uses scikit-learn models trained on historical data:

1. **Feature Engineering**: Extracts time, occupancy, weather, recent states
2. **Model Training**: Uses GradientBoosting and RandomForest classifiers
3. **Prediction Generation**: Produces predictions with confidence scores
4. **Blending**: Combines multiple models for better accuracy

### Reading Prediction Cards

**Green Border**: High confidence (≥75%)
**Yellow Border**: Medium confidence (60-74%)
**Red Border**: Low confidence (<60%)

**Indicators:**
- **Clock Icon**: Time until predicted state change
- **Percentage**: Confidence score
- **History Icon**: Link to view prediction history

### When to Trust Predictions

**Trust when:**
- Confidence is ≥75%
- Pattern matches known behavior
- Entity has stable historical data

**Be cautious when:**
- Confidence is <60%
- Pattern is newly detected
- Entity has irregular behavior

### Prediction Accuracy

View accuracy metrics on Predictions page:
- **Overall Accuracy**: Percentage of correct predictions
- **Per-Entity Accuracy**: Accuracy for each entity
- **Per-Horizon Accuracy**: Accuracy by time horizon

**Expected accuracy:**
- 5-min horizon: 85-95%
- 15-min horizon: 75-85%
- 1-hour horizon: 65-75%
- 4-hour horizon: 55-65%

## Pattern Analysis

### How Patterns Are Detected

1. **Data Collection**: Logbook entries from Home Assistant
2. **Sequence Extraction**: Identifies state change sequences
3. **LLM Analysis**: Ollama qwen2.5:7b interprets patterns
4. **Confidence Scoring**: Rates pattern reliability

### Pattern Interpretation

**Example Pattern:**
```json
{
  "name": "Morning Routine",
  "description": "Lights turn on in sequence: bedroom → bathroom → kitchen between 6-7 AM on weekdays",
  "trigger": "time",
  "conditions": ["day in [mon, tue, wed, thu, fri]", "time between 06:00-07:00"],
  "entities": ["light.bedroom", "light.bathroom", "light.kitchen"],
  "frequency": "weekdays",
  "confidence": 0.91
}
```

**Key Elements:**
- **Name**: Human-readable pattern identifier
- **Description**: Natural language explanation
- **Trigger**: What initiates the pattern (time, occupancy, sensor)
- **Conditions**: When the pattern applies
- **Entities**: Devices involved
- **Frequency**: How often pattern occurs
- **Confidence**: Reliability score (0-1)

### Using Patterns

**Convert to Automation:**
1. Review pattern details
2. Click "Create Automation"
3. Hub generates automation proposal
4. Review and approve on Automations page

**Disable Pattern:**
If a pattern is no longer relevant (e.g., seasonal behavior), click "Ignore Pattern" to exclude it from future automation proposals.

## Automation Approvals

### Review Process

1. **Receive Proposal**: Hub generates automation based on patterns or predictions
2. **Review Details**: Check trigger, conditions, actions
3. **Test (Optional)**: Click "Simulate" to see what would happen
4. **Approve or Reject**: Make decision

### Approval Checklist

Before approving, verify:
- [ ] Trigger is correct (time, sensor, state change)
- [ ] Conditions prevent unwanted activations
- [ ] Actions are safe (won't damage devices)
- [ ] Confidence score is acceptable (≥75% recommended)
- [ ] Pattern matches your actual behavior

### Editing Proposals

Click "Edit" to modify before approval:
- **Adjust Trigger**: Change time, sensor threshold
- **Add Conditions**: Prevent activation in certain scenarios
- **Modify Actions**: Change target state, brightness, etc.

### After Approval

Once approved:
1. Hub calls HA API to create automation
2. Automation appears in HA UI (Settings → Automations)
3. Status changes to "Approved" in dashboard
4. Effectiveness tracking begins

**To modify later:**
- Edit in Home Assistant UI
- Or reject and re-approve with changes in hub

## Troubleshooting

### Dashboard Won't Load

**Check hub is running:**
```bash
systemctl --user status aria-hub.service
```

**Test health endpoint:**
```bash
curl http://localhost:8000/health
```

**Check logs:**
```bash
journalctl --user -u aria-hub.service -n 50
```

### No Predictions Showing

**Causes:**
1. Insufficient training data (need 7+ days)
2. ML engine not initialized
3. No capabilities discovered

**Solutions:**
1. Wait for training data to accumulate
2. Check ML engine status in Home page
3. Run discovery manually

### Patterns Not Detected

**Causes:**
1. Insufficient logbook data (need 24+ hours)
2. Irregular behavior (no consistent patterns)
3. Pattern recognition module not running

**Solutions:**
1. Wait for more data
2. Review logbook manually to confirm patterns exist
3. Check Patterns module status

### Automation Approval Failed

**Check logs:**
```bash
journalctl --user -u aria-hub.service | grep -i "automation"
```

**Common issues:**
- HA API token expired (regenerate in HA UI)
- Invalid entity ID (verify entity still exists)
- HA unavailable (check network connection)

**Retry approval:**
1. Fix underlying issue
2. Click "Retry" on automation card

### Cache Errors

**SQLite database locked:**
```bash
systemctl --user restart aria-hub.service
```

**Corrupted cache:**
```bash
# Backup first
cp ~/ha-logs/intelligence/cache/hub.db ~/ha-logs/intelligence/cache/hub.db.backup

# Clear cache
rm ~/ha-logs/intelligence/cache/hub.db

# Restart hub (will recreate cache)
systemctl --user restart aria-hub.service
```

### High Memory Usage

**Check memory:**
```bash
systemctl --user status aria-hub.service | grep Memory
```

**Reduce memory:**
1. Lower cache size in `hub/cache.py`
2. Reduce ML model complexity
3. Increase training interval

### Dashboard Performance Issues

**Slow page loads:**
- Reduce number of entities displayed
- Increase cache TTL
- Use pagination for large lists

**WebSocket disconnects:**
- Check network stability
- Increase WebSocket timeout in browser
- Monitor hub logs for errors

## Advanced Usage

### API Access

All dashboard data is accessible via REST API:

```bash
# Get capabilities
curl http://localhost:8000/api/cache/capabilities | jq

# Get predictions
curl http://localhost:8000/api/cache/ml_predictions | jq

# Get patterns
curl http://localhost:8000/api/cache/detected_patterns | jq
```

### Custom Dashboards

Use WebSocket for real-time updates in custom UIs:

```javascript
const ws = new WebSocket('ws://localhost:8000/ws');

ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  console.log('Update:', data);
};
```

### Exporting Data

Export cache data for analysis:

```bash
# Export full cache
sqlite3 ~/ha-logs/intelligence/cache/hub.db .dump > cache_export.sql

# Export specific category
sqlite3 ~/ha-logs/intelligence/cache/hub.db \
  "SELECT data FROM cache WHERE category='capabilities'" | jq
```

## FAQ

**Q: How often does discovery run?**
A: Every 24 hours by default. Configurable in `bin/ha-hub.py`.

**Q: Can I manually trigger ML training?**
A: Yes, via API: `curl -X POST http://localhost:8000/api/ml/train`

**Q: How is confidence calculated?**
A: Based on model probability scores and historical accuracy.

**Q: Can I use multiple LLMs for pattern detection?**
A: Yes, modify `modules/patterns.py` to use different Ollama models.

**Q: Does the hub work offline?**
A: Partially. Discovery and ML work offline. Pattern recognition requires Ollama (local).

**Q: How much disk space does the cache use?**
A: Typically 10-50 MB, depending on entity count and history depth.

**Q: Can I run multiple hubs for different HA instances?**
A: Yes, use different ports and cache directories.
